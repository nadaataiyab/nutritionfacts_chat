{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import hub\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_core.runnables import (\n",
    "    ConfigurableField,\n",
    "    RunnableBinding,\n",
    "    RunnableLambda,\n",
    "    RunnablePassthrough,\n",
    "    RunnableParallel\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_colwidth', 300)  # Or use a large number if 'None' does not work in some environments\n",
    "pd.set_option('display.max_columns', 300)  # Show all columns\n",
    "pd.set_option('display.max_rows', 20)  # Show all row\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_APIKEY = os.environ['OPENAI_APIKEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out tools\n",
    "-https://python.langchain.com/docs/modules/tools/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikipedia\n",
      "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
      "<class 'pydantic.v1.main.wikipediaSchema'>\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n",
      "False\n",
      "<class 'pydantic.v1.main.wikipedia_output'>\n"
     ]
    }
   ],
   "source": [
    "print(tool.name)\n",
    "print(tool.description)\n",
    "print(tool.input_schema)\n",
    "print(tool.args)\n",
    "print(tool.return_direct)\n",
    "print(tool.output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.invoke(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class WikiInputs(BaseModel):\n",
    "    \"\"\"Inputs to the wikipedia tool.\"\"\"\n",
    "\n",
    "    query: str = Field(\n",
    "        description=\"query to look up in Wikipedia, should be 3 or less words\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = WikipediaQueryRun(\n",
    "    name=\"wiki-tool\",\n",
    "    description=\"look up things in wikipedia\",\n",
    "    args_schema=WikiInputs,\n",
    "    api_wrapper=api_wrapper,\n",
    "    return_direct=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.pubmed.tool import PubmedQueryRun\n",
    "\n",
    "tool = PubmedQueryRun()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'title': 'Query', 'type': 'string'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Custom Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Look up things online.\"\"\"\n",
    "    return \"LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search\n",
      "search(query: str) -> str - Look up things online.\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return f\"The answer is: {a * b}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "multiply(a: int, b: int) -> int - Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer is: 2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({'a':1, 'b':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")\n",
    "\n",
    "\n",
    "@tool(\"search-tool\", args_schema=SearchInput, return_direct=True)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Look up things online.\"\"\"\n",
    "    return \"LangChain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': {'title': 'Query', 'description': 'should be a search query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(search.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools from Structured Data Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_function(query: str):\n",
    "    return \"LangChain\"\n",
    "\n",
    "\n",
    "search = StructuredTool.from_function(\n",
    "    func=search_function,\n",
    "    name=\"Search\",\n",
    "    description=\"useful for when you need to answer questions about current events\",\n",
    "    # coroutine= ... <- you can specify an async method if desired as well\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search\n",
      "Search(query: str) - useful for when you need to answer questions about current events\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(search.name)\n",
    "print(search.description)\n",
    "print(search.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool with error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import ToolException\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "    c: int = Field(description=\"third number\")\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int, c: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    try:\n",
    "        return a * b + 'c'  #put a mistake here\n",
    "    except:\n",
    "        raise ToolException(\"This search tool is not available\")\n",
    "\n",
    "\n",
    "calculator = StructuredTool.from_function(\n",
    "    func=multiply,\n",
    "    name=\"Calculator\",\n",
    "    description=\"multiply numbers\",\n",
    "    args_schema=CalculatorInput,\n",
    "    return_direct=True,\n",
    "    handle_tool_error=True\n",
    "    # coroutine= ... <- you can specify an async method if desired as well\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This search tool is not available'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator.invoke({'a': 1, 'b': 2, 'c': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools as OpenAI Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import MoveFileTool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='Calculator', description='Calculator(a: int, b: int, c: int) -> int - multiply numbers', args_schema=<class '__main__.CalculatorInput'>, return_direct=True, handle_tool_error=True, func=<function multiply at 0x12de7a520>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(api_key=OPENAI_APIKEY, model=\"gpt-3.5-turbo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'move_file',\n",
       " 'description': 'Move or rename a file from one location to another',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'source_path': {'description': 'Path of the file to move',\n",
       "    'type': 'string'},\n",
       "   'destination_path': {'description': 'New path for the moved file',\n",
       "    'type': 'string'}},\n",
       "  'required': ['source_path', 'destination_path']}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [MoveFileTool()]\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "functions[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = model.invoke(\n",
    "    [HumanMessage(content=\"move file foo to bar\")], functions=functions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"source_path\":\"foo\",\"destination_path\":\"bar\"}', 'name': 'move_file'}}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 77, 'total_tokens': 97}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-0549b5d0-d480-4fa8-82ba-649d839d2827-0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'arguments': '{\"source_path\":\"foo\",\"destination_path\":\"bar\"}',\n",
       "  'name': 'move_file'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't need to put the human message class here and it still works\n",
    "message = model.invoke(\n",
    "    \"move file from foo to bar\", functions=functions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'arguments': '{\"source_path\":\"foo\",\"destination_path\":\"bar\"}',\n",
       "  'name': 'move_file'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"source_path\":\"foo\",\"destination_path\":\"bar\"}', 'name': 'move_file'}}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 78, 'total_tokens': 98}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-d8570eee-9f96-4dad-b801-cf69aadf8a8f-0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"source_path\":\"foo\",\"destination_path\":\"bar\"}', 'name': 'move_file'}}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 77, 'total_tokens': 97}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-b7c9fe46-0922-4d48-b9aa-52b1826d7eae-0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use openai to automatically bind functions\n",
    "model_with_functions = model.bind_functions(tools)\n",
    "model_with_functions.invoke(\"move file foo to bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why couldn't the bicycle find its way home? Because it lost its bearings!\", response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 76, 'total_tokens': 93}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8b7ea077-e66c-44d5-a1d2-b23de24a1ea5-0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_functions.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure the difference between model with functions vs model with tools and binding the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_7yWO3AH4pJ1FXrVdWrri6DKe', 'function': {'arguments': '{\"source_path\":\"foo\",\"destination_path\":\"bar\"}', 'name': 'move_file'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 77, 'total_tokens': 97}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-8bec4525-2665-4268-962c-767cb09e4842-0', tool_calls=[{'name': 'move_file', 'args': {'source_path': 'foo', 'destination_path': 'bar'}, 'id': 'call_7yWO3AH4pJ1FXrVdWrri6DKe'}])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use OpenAI tools and tool choice here too\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "model_with_tools.invoke([HumanMessage(content=\"move file foo to bar\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\", response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 76, 'total_tokens': 90}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8e874787-f4a5-4027-889e-72b9092669fe-0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use OpenAI tools and tool choice here too\n",
    "# See it knows when to use the tool!!\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "model_with_tools.invoke([HumanMessage(content=\"tell me a joke\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I will need the source path and the destination path to move the file. Could you please provide me with this information?', response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 77, 'total_tokens': 102}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f60b543a-75b6-4f15-9336-9923595fd693-0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools = model.bind_tools(tools)\n",
    "model_with_tools.invoke([HumanMessage(content=\"Move the file from foo\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow it even knew it couldn't call the tool becuase i didnt give the destination path!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call multiple tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools\n",
    "class WaterQuestionInput(BaseModel):\n",
    "    gender: str = Field(description=\"Answer with Male, Female, or Other\")\n",
    "    age: int\n",
    "\n",
    "\n",
    "@tool(\"waterquestion-tool\", args_schema=WaterQuestionInput, return_direct=True)\n",
    "def WaterQuestion(gender: str, age: int ) -> str:\n",
    "    \"\"\"Look up water recommendations based on age and gender\"\"\"\n",
    "    answer = f\"For {gender} aged {age}, you should drink 8 cups a day\"\n",
    "    return answer\n",
    "\n",
    "class ProteinQuestionInput(BaseModel):\n",
    "    gender: str = Field(description=\"Answer with Male, Female, or Other\")\n",
    "    age: int\n",
    "    weight: float\n",
    "\n",
    "@tool(\"proteinquestion-tool\", args_schema=ProteinQuestionInput, return_direct=True)\n",
    "def ProteinQuestion(gender: str, age: int, weight: int ) -> str:\n",
    "    \"\"\"Look up water recommendations based on age, gender, and weight.\"\"\"\n",
    "    answer = f\"For {gender} aged {age} weighing {weight}, you should \\\n",
    "         eat 1g of protein per kg.\"\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to openai functions\n",
    "water_function = convert_to_openai_function(WaterQuestion)\n",
    "protein_function = convert_to_openai_function(ProteinQuestion)\n",
    "tools = [water_function, protein_function]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "model = ChatOpenAI(api_key=OPENAI_APIKEY, model=\"gpt-4-turbo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the tools\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='To provide you with accurate information on how much water you should drink, I need to know your age and gender. Could you please provide that information?', response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 153, 'total_tokens': 184}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_294de9593d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ae1dcbad-9009-4a64-bb55-6000d7adbed5-0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try it out\n",
    "model_with_tools.invoke(\"How much water should I drink?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note!! Wtih gpt 3.5 it hallucinates the inputs - making up age and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_p9rvWO9m6HH942fgsyQxNhE8', 'function': {'arguments': '{\"gender\":\"Female\",\"age\":30}', 'name': 'waterquestion-tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 159, 'total_tokens': 178}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_294de9593d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d368b5a6-af1e-46c2-8c54-1e4397381e33-0', tool_calls=[{'name': 'waterquestion-tool', 'args': {'gender': 'Female', 'age': 30}, 'id': 'call_p9rvWO9m6HH942fgsyQxNhE8'}])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke(\"How much water should I drink as a female aged 30?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_lDeU1547IimJEWD7AsEgOmI7', 'function': {'arguments': '{\"gender\":\"Male\",\"age\":30,\"weight\":200}', 'name': 'proteinquestion-tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 165, 'total_tokens': 189}, 'model_name': 'gpt-4-turbo', 'system_fingerprint': 'fp_ea6eb70039', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d99297fe-6d8b-43a4-ae13-f591e3a83e98-0', tool_calls=[{'name': 'proteinquestion-tool', 'args': {'gender': 'Male', 'age': 30, 'weight': 200}, 'id': 'call_lDeU1547IimJEWD7AsEgOmI7'}])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools.invoke(\"How much protein should I eat as a male, aged 30, weighing 200 lbs?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Executor\n",
    "- Use an agent to actually execute on the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt must have an agent scratch pad\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't convert the tools to the openai format before putting them into the\n",
    "# openai agent\n",
    "tools = [ProteinQuestion, WaterQuestion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First construct an agent\n",
    "# Construct the OpenAI Functions agent\n",
    "agent = create_openai_functions_agent(model, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct something to execute on the agent\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo provide an accurate protein recommendation, I need to know the weight of the individual. Could you please provide the weight of the 30-year-old female?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How much protein should a female aged 30 eat?',\n",
       " 'output': 'To provide an accurate protein recommendation, I need to know the weight of the individual. Could you please provide the weight of the 30-year-old female?'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': 'How much protein should a female aged 30 eat?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `proteinquestion-tool` with `{'gender': 'Female', 'age': 30, 'weight': 120}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mFor Female aged 30 weighing 120.0, you should          eat 1g of protein per kg.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How much protein should a female aged 30 weighing 120 lbs eat?',\n",
       " 'output': 'For Female aged 30 weighing 120.0, you should          eat 1g of protein per kg.'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': 'How much protein should a female aged 30 weighing 120 lbs eat?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nutritionfacts_chat-G3oMJuqJ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
